{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#gnomonicus","title":"gnomonicus","text":"<p>Python code to integrate results of tb-pipeline and provide an antibiogram, mutations and variations</p> <p>Provides a library of functions for use within scripts, as well as a CLI tool for linking the functions together to produce output</p>"},{"location":"#documentation","title":"Documentation","text":"<p>API reference for developers, and CLI instructions can be found here: https://oxfordmmm.github.io/gnomonicus/ </p>"},{"location":"#usage","title":"Usage","text":"<pre><code>usage: gnomonicus [-h] [-v] --vcf_file VCF_FILE --genome_object GENOME_OBJECT [--catalogue_file CATALOGUE_FILE] [--ignore_vcf_filter] [--output_dir OUTPUT_DIR] [--json] [--csvs CSVS [CSVS ...]] [--debug]\n                  [--resistance_genes] --min_dp MIN_DP\n\noptions:\n  -h, --help            show this help message and exit\n  -v, --version         show program's version number and exit\n  --vcf_file VCF_FILE   the path to a single VCF file\n  --genome_object GENOME_OBJECT\n                        the path to a genbank file\n  --catalogue_file CATALOGUE_FILE\n                        the path to the resistance catalogue\n  --ignore_vcf_filter   whether to ignore the FILTER field in the vcf (e.g. necessary for some versions of Clockwork VCFs)\n  --output_dir OUTPUT_DIR\n                        Directory to save output files to. Defaults to wherever the script is run from.\n  --json                Flag to create a single JSON output as well as the CSVs\n  --csvs CSVS [CSVS ...]\n                        Types of CSV to produce. Accepted values are [variants, mutations, effects, predictions, all]. `all` produces all of the CSVs\n  --debug               Whether to log debugging messages to the log. Defaults to False\n  --resistance_genes    Flag to filter mutations and variants to only include genes present in the resistance catalogue\n  --min_dp MIN_DP       Minimum depth for a variant to be considered in the VCF. Below this value, rows are interpreted as null calls.\n</code></pre>"},{"location":"#install","title":"Install","text":"<p>Simple install using pip for the latest release</p> <pre><code>pip install gnomonicus\n</code></pre> <p>Install from source</p> <pre><code>git clone https://github.com/oxfordmmm/gnomonicus.git\ncd gnomonicus\npip install -e .\n</code></pre>"},{"location":"#docker","title":"Docker","text":"<p>A Docker image should be built on releases. To open a shell with gnomonicus installed:</p> <pre><code>docker run -it oxfordmmm/gnomonicus:latest\n</code></pre>"},{"location":"#notes","title":"Notes","text":"<p>When generating mutations, in cases of synonymous amino acid mutation, the nucelotides changed are also included. This can lead to a mix of nucleotides and amino acids for coding genes, but these are excluded from generating effects unless specified in the catalogue. This means that the default rule of <code>gene@*= --&gt; S</code> is still in place regardless of the introduced <code>gene@*?</code> which would otherwise take precedence. For example:</p> <pre><code>  'MUTATIONS': [\n      {\n          'MUTATION': 'F2F',\n          'GENE': 'S',\n          'GENE_POSITION': 2\n      },\n      {\n          'MUTATION': 't6c',\n          'GENE': 'S',\n          'GENE_POSITION': 6\n      },\n  ],\n  'EFFECTS': {\n      'AAA': [\n          {\n              'GENE': 'S',\n              'MUTATION': 'F2F',\n              'PREDICTION': 'S'\n          },\n          {\n              'PHENOTYPE': 'S'\n          }\n      ],\n  }\n</code></pre> <p>The nucelotide variation is included in the the <code>MUTATIONS</code>, but explictly removed from the <code>EFFECTS</code> unless it is specified within the catalogue. In order for this variation to be included, a line in the catalogue of <code>S@F2F&amp;S@t6c</code> would have to be present.</p>"},{"location":"#user-stories","title":"User stories","text":"<ol> <li> <p>As a bioinformatician, I want to be able to run <code>gnomonicus</code> on the command line, passing it (i) a GenBank file ~~(or pickled <code>gumpy.Genome</code> object)~~, (ii) a resistance catalogue and (iii) a VCF file, and get back <code>pandas.DataFrames</code> of the genetic variants, mutations, effects and predictions/antibiogram. The latter is for all the drugs described in the passed resistance catalogue.</p> </li> <li> <p>As a GPAS developer, I want to be able to embed <code>gnomonicus</code> in a Docker image/NextFlow pipeline that consumes the outputs of tb-pipeline and emits a structured, well-designed <code>JSON</code> object describing the genetic variants, mutations, effects and predictions/antibiogram.</p> </li> <li> <p>In general, I would also like the option to output fixed- and variable-length FASTA files (the latter takes into account insertions and deletions described in any input VCF file).</p> </li> </ol>"},{"location":"#unit-testing","title":"Unit testing","text":"<p>For speed, rather than use NC_000962.3 (i.e. H37Rv M. tuberculosis), we shall use SARS-CoV-2 and have created a fictious drug resistance catalogue, along with some <code>vcf</code> files and the expected outputs in <code>tests/</code>.</p> <p>These can be run with <code>pytest -vv</code></p>"},{"location":"bin/","title":"gnomonicus","text":"<p><code>gnomonicus</code> is a script which links together the functions defined in gnomonicus.py as a CLI script to produce variants, mutations and an antibiogram from a minos VCF, reference genome and a resistance catalogue.</p> <pre><code>usage: gnomonicus [-h] [-v] --vcf_file VCF_FILE --genome_object GENOME_OBJECT [--catalogue_file CATALOGUE_FILE] [--ignore_vcf_filter] [--output_dir OUTPUT_DIR] [--json] [--csvs CSVS [CSVS ...]] [--debug]\n                  [--resistance_genes] --min_dp MIN_DP\n\noptions:\n  -h, --help            show this help message and exit\n  -v, --version         show program's version number and exit\n  --vcf_file VCF_FILE   the path to a single VCF file\n  --genome_object GENOME_OBJECT\n                        the path to a genbank file\n  --catalogue_file CATALOGUE_FILE\n                        the path to the resistance catalogue\n  --ignore_vcf_filter   whether to ignore the FILTER field in the vcf (e.g. necessary for some versions of Clockwork VCFs)\n  --output_dir OUTPUT_DIR\n                        Directory to save output files to. Defaults to wherever the script is run from.\n  --json                Flag to create a single JSON output as well as the CSVs\n  --csvs CSVS [CSVS ...]\n                        Types of CSV to produce. Accepted values are [variants, mutations, effects, predictions, all]. `all` produces all of the CSVs\n  --debug               Whether to log debugging messages to the log. Defaults to False\n  --resistance_genes    Flag to filter mutations and variants to only include genes present in the resistance catalogue\n  --min_dp MIN_DP       Minimum depth for a variant to be considered in the VCF. Below this value, rows are interpreted as null calls.\n</code></pre>"},{"location":"bin/#merge-vcfs","title":"merge-vcfs","text":"<p>Script for merging a minos VCF with a gvcf file at specific positions for including null calls at certain positions. Required as minos will not consistently report null calls at all positions, and we want to be able to highlight occasions that we have null calls on resistance determining sites.</p> <pre><code>usage: merge-vcfs [-h] --minos_vcf MINOS_VCF --gvcf GVCF --resistant-positions RESISTANT_POSITIONS --output OUTPUT\n\nMerge a minos VCF with a GVCF at certain positions (driven by the catalogue).\n\noptions:\n  -h, --help            show this help message and exit\n  --minos_vcf MINOS_VCF\n                        The minos VCF filepath\n  --gvcf GVCF           The GVCF filepath\n  --resistant-positions RESISTANT_POSITIONS\n                        Path to list of resistant sites\n  --output OUTPUT       The output VCF file path\n\n</code></pre>"},{"location":"readme/","title":"Home","text":""},{"location":"readme/#gnomonicus","title":"gnomonicus","text":"<p>Python code to integrate results of tb-pipeline and provide an antibiogram, mutations and variations</p> <p>Provides a library of functions for use within scripts, as well as a CLI tool for linking the functions together to produce output</p>"},{"location":"readme/#documentation","title":"Documentation","text":"<p>API reference for developers, and CLI instructions can be found here: https://oxfordmmm.github.io/gnomonicus/ </p>"},{"location":"readme/#usage","title":"Usage","text":"<pre><code>usage: gnomonicus [-h] [-v] --vcf_file VCF_FILE --genome_object GENOME_OBJECT [--catalogue_file CATALOGUE_FILE] [--ignore_vcf_filter] [--output_dir OUTPUT_DIR] [--json] [--csvs CSVS [CSVS ...]] [--debug]\n                  [--resistance_genes] --min_dp MIN_DP\n\noptions:\n  -h, --help            show this help message and exit\n  -v, --version         show program's version number and exit\n  --vcf_file VCF_FILE   the path to a single VCF file\n  --genome_object GENOME_OBJECT\n                        the path to a genbank file\n  --catalogue_file CATALOGUE_FILE\n                        the path to the resistance catalogue\n  --ignore_vcf_filter   whether to ignore the FILTER field in the vcf (e.g. necessary for some versions of Clockwork VCFs)\n  --output_dir OUTPUT_DIR\n                        Directory to save output files to. Defaults to wherever the script is run from.\n  --json                Flag to create a single JSON output as well as the CSVs\n  --csvs CSVS [CSVS ...]\n                        Types of CSV to produce. Accepted values are [variants, mutations, effects, predictions, all]. `all` produces all of the CSVs\n  --debug               Whether to log debugging messages to the log. Defaults to False\n  --resistance_genes    Flag to filter mutations and variants to only include genes present in the resistance catalogue\n  --min_dp MIN_DP       Minimum depth for a variant to be considered in the VCF. Below this value, rows are interpreted as null calls.\n</code></pre>"},{"location":"readme/#install","title":"Install","text":"<p>Simple install using pip for the latest release</p> <pre><code>pip install gnomonicus\n</code></pre> <p>Install from source</p> <pre><code>git clone https://github.com/oxfordmmm/gnomonicus.git\ncd gnomonicus\npip install -e .\n</code></pre>"},{"location":"readme/#docker","title":"Docker","text":"<p>A Docker image should be built on releases. To open a shell with gnomonicus installed:</p> <pre><code>docker run -it oxfordmmm/gnomonicus:latest\n</code></pre>"},{"location":"readme/#notes","title":"Notes","text":"<p>When generating mutations, in cases of synonymous amino acid mutation, the nucelotides changed are also included. This can lead to a mix of nucleotides and amino acids for coding genes, but these are excluded from generating effects unless specified in the catalogue. This means that the default rule of <code>gene@*= --&gt; S</code> is still in place regardless of the introduced <code>gene@*?</code> which would otherwise take precedence. For example:</p> <pre><code>  'MUTATIONS': [\n      {\n          'MUTATION': 'F2F',\n          'GENE': 'S',\n          'GENE_POSITION': 2\n      },\n      {\n          'MUTATION': 't6c',\n          'GENE': 'S',\n          'GENE_POSITION': 6\n      },\n  ],\n  'EFFECTS': {\n      'AAA': [\n          {\n              'GENE': 'S',\n              'MUTATION': 'F2F',\n              'PREDICTION': 'S'\n          },\n          {\n              'PHENOTYPE': 'S'\n          }\n      ],\n  }\n</code></pre> <p>The nucelotide variation is included in the the <code>MUTATIONS</code>, but explictly removed from the <code>EFFECTS</code> unless it is specified within the catalogue. In order for this variation to be included, a line in the catalogue of <code>S@F2F&amp;S@t6c</code> would have to be present.</p>"},{"location":"readme/#user-stories","title":"User stories","text":"<ol> <li> <p>As a bioinformatician, I want to be able to run <code>gnomonicus</code> on the command line, passing it (i) a GenBank file ~~(or pickled <code>gumpy.Genome</code> object)~~, (ii) a resistance catalogue and (iii) a VCF file, and get back <code>pandas.DataFrames</code> of the genetic variants, mutations, effects and predictions/antibiogram. The latter is for all the drugs described in the passed resistance catalogue.</p> </li> <li> <p>As a GPAS developer, I want to be able to embed <code>gnomonicus</code> in a Docker image/NextFlow pipeline that consumes the outputs of tb-pipeline and emits a structured, well-designed <code>JSON</code> object describing the genetic variants, mutations, effects and predictions/antibiogram.</p> </li> <li> <p>In general, I would also like the option to output fixed- and variable-length FASTA files (the latter takes into account insertions and deletions described in any input VCF file).</p> </li> </ol>"},{"location":"readme/#unit-testing","title":"Unit testing","text":"<p>For speed, rather than use NC_000962.3 (i.e. H37Rv M. tuberculosis), we shall use SARS-CoV-2 and have created a fictious drug resistance catalogue, along with some <code>vcf</code> files and the expected outputs in <code>tests/</code>.</p> <p>These can be run with <code>pytest -vv</code></p>"},{"location":"reference/","title":"gnomonicus","text":"<p>gnomonicus is a library providing functions which pull together output VCF of the Lodestone TB pipeline     with a reference genome and a resistance catalogue, and utilise gumpy and     piezo to produce variants, mutations and an antibiogram.</p> <p>Provides a CLI script (bin/gnomonicus) which links these functions together to produce all outputs from the inputs. Makes the assumption that VCF files are named <code>&lt;GUID&gt;.vcf</code></p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>gnomonicus</li> <li>gnomonicus_lib</li> </ul>"},{"location":"reference/gnomonicus_lib/","title":"gnomonicus_lib","text":"<p>gnomonicus.py is a library providing functions which pull together output VCF of the Lodestone TB pipeline     with a reference genome and a resistance catalogue, and utilise grumpy and     piezo to produce variants, mutations and an antibiogram.</p> <p>Based on sp3predict</p>"},{"location":"reference/gnomonicus_lib/#gnomonicus_lib.InvalidMutationException","title":"<code>InvalidMutationException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Custom exception raised when an invalid mutation is detected</p> Source code in <code>gnomonicus/gnomonicus_lib.py</code> <pre><code>class InvalidMutationException(Exception):\n    \"\"\"Custom exception raised when an invalid mutation is detected\"\"\"\n\n    def __init__(self, gene: str, mutation: str):\n        \"\"\"Raise this exception\n\n        Args:\n            gene (str): Name of the gene\n            mutation (str): The invalid mutation\n        \"\"\"\n        self.message = f\"{gene}@{mutation} is not a valid mutation!\"\n        super().__init__(self.message)\n</code></pre>"},{"location":"reference/gnomonicus_lib/#gnomonicus_lib.InvalidMutationException.__init__","title":"<code>__init__(gene, mutation)</code>","text":"<p>Raise this exception</p> <p>Parameters:</p> Name Type Description Default <code>gene</code> <code>str</code> <p>Name of the gene</p> required <code>mutation</code> <code>str</code> <p>The invalid mutation</p> required Source code in <code>gnomonicus/gnomonicus_lib.py</code> <pre><code>def __init__(self, gene: str, mutation: str):\n    \"\"\"Raise this exception\n\n    Args:\n        gene (str): Name of the gene\n        mutation (str): The invalid mutation\n    \"\"\"\n    self.message = f\"{gene}@{mutation} is not a valid mutation!\"\n    super().__init__(self.message)\n</code></pre>"},{"location":"reference/gnomonicus_lib/#gnomonicus_lib.count_nucleotide_changes","title":"<code>count_nucleotide_changes(ref, alt)</code>","text":"<p>Count number of changes between ref and alt</p> <p>Parameters:</p> Name Type Description Default <code>ref</code> <code>str | None</code> <p>Ref nucleotides</p> required <code>alt</code> <code>str | None</code> <p>Alt nucleotides</p> required <p>Returns:</p> Type Description <code>int | None</code> <p>int | None: SNP distance if SNP, None if ref/alt were None</p> Source code in <code>gnomonicus/gnomonicus_lib.py</code> <pre><code>def count_nucleotide_changes(ref: str | None, alt: str | None) -&gt; int | None:\n    \"\"\"Count number of changes between ref and alt\n\n    Args:\n        ref (str | None): Ref nucleotides\n        alt (str | None): Alt nucleotides\n\n    Returns:\n        int | None: SNP distance if SNP, None if ref/alt were None\n    \"\"\"\n    if ref is None or alt is None:\n        return None\n    return sum(1 for r, a in zip(ref, alt) if r != a)\n</code></pre>"},{"location":"reference/gnomonicus_lib/#gnomonicus_lib.epistasis","title":"<code>epistasis(mutations, resistanceCatalogue, phenotype, effects, effectsCounter, vcfStem)</code>","text":"<p>Add epistasis rules, overriding existing predictions as required</p> <p>Parameters:</p> Name Type Description Default <code>mutations</code> <code>list[tuple[str | None, str]]</code> <p>Sample's mutations. Items are tuples of (gene, mutation)</p> required <code>resistanceCatalogue</code> <code>ResistanceCatalogue</code> <p>Resistance catalogue to use</p> required <code>phenotype</code> <code>dict</code> <p>Dictionary of phenotypes</p> required <code>effects</code> <code>dict</code> <p>Dictionary of effects</p> required <code>effectsCounter</code> <code>int</code> <p>Position to add to effects dict</p> required <code>vcfStem</code> <code>str</code> <p>Stem of the VCF file. Used as the <code>uniqueid</code></p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Incremented effects counter</p> Implicit returns <p>phenotypes: dict is updated in place effects: dict is updated in place</p> Source code in <code>gnomonicus/gnomonicus_lib.py</code> <pre><code>def epistasis(\n    mutations: list[tuple[str | None, str]],\n    resistanceCatalogue: piezo.ResistanceCatalogue,\n    phenotype: dict,\n    effects: dict,\n    effectsCounter: int,\n    vcfStem: str,\n) -&gt; int:\n    \"\"\"Add epistasis rules, overriding existing predictions as required\n\n    Args:\n        mutations (list[tuple[str | None, str]]): Sample's mutations. Items are tuples of (gene, mutation)\n        resistanceCatalogue (piezo.ResistanceCatalogue): Resistance catalogue to use\n        phenotype (dict): Dictionary of phenotypes\n        effects (dict): Dictionary of effects\n        effectsCounter (int): Position to add to effects dict\n        vcfStem (str): Stem of the VCF file. Used as the `uniqueid`\n\n    Returns:\n        int: Incremented effects counter\n\n    Implicit returns:\n        phenotypes: dict is updated in place\n        effects: dict is updated in place\n    \"\"\"\n    epi_rules = set(\n        resistanceCatalogue.catalogue.rules[\n            resistanceCatalogue.catalogue.rules[\"MUTATION_TYPE\"] == \"EPISTASIS\"\n        ][\"MUTATION\"]\n    )\n    if len(epi_rules) &gt; 0:\n        # We have some epistasis rules so deal with them\n        mutations = subset_multis(epi_rules, mutations, just_joined=True)\n        seen_multis = set([effects[key][2] for key in effects.keys()])\n        for _, mutation in mutations:\n            prediction = resistanceCatalogue.predict(mutation, show_evidence=True)\n            if isinstance(prediction, str):\n                # prediction == \"S\" but mypy doesn't like that\n                # Default prediction so ignore (not that this should happen here)\n                continue\n            for drug in prediction.keys():\n                pred = prediction[drug]\n                if isinstance(pred, str):\n                    # Shouldn't be hit but mypy complains\n                    pred = pred\n                    evidence = None\n                else:\n                    pred, evidence = pred\n                if phenotype[drug] != \"F\":\n                    # F is the only value which overrides epistasis rules\n                    phenotype[drug] = pred\n                # Add to the dict if not already seen\n                # It's possible that this exact multi already hit an epistasis rule\n                if mutation not in seen_multis:\n                    effects[effectsCounter] = [\n                        vcfStem,\n                        None,\n                        mutation,\n                        resistanceCatalogue.catalogue.name,\n                        drug,\n                        pred,\n                        evidence,\n                    ]\n                    # Increment counter\n                    effectsCounter += 1\n    return effectsCounter\n</code></pre>"},{"location":"reference/gnomonicus_lib/#gnomonicus_lib.getGenes","title":"<code>getGenes(sample, resistanceCatalogue, resistanceGenesOnly)</code>","text":"<p>Get the genes we're interested in.</p> <p>This is either just resistance genes which have variants, or all which have variants</p> <p>Parameters:</p> Name Type Description Default <code>sample</code> <code>Genome</code> <p>Sample's genome object</p> required <code>resistanceCatalogue</code> <code>ResistanceCatalogue</code> <p>Resistance catalogue</p> required <code>resistanceGenesOnly</code> <code>bool</code> <p>Whether to just use genes within the catalogue</p> required <p>Returns:</p> Type Description <code>set</code> <p>set[str]: Set of gene names</p> Source code in <code>gnomonicus/gnomonicus_lib.py</code> <pre><code>def getGenes(\n    sample: grumpy.Genome,\n    resistanceCatalogue: piezo.ResistanceCatalogue,\n    resistanceGenesOnly: bool,\n) -&gt; set:\n    \"\"\"Get the genes we're interested in.\n\n    This is either just resistance genes which have variants, or all which have variants\n\n    Args:\n        sample (grumpy.Genome): Sample's genome object\n        resistanceCatalogue (piezo.ResistanceCatalogue): Resistance catalogue\n        resistanceGenesOnly (bool): Whether to just use genes within the catalogue\n\n    Returns:\n        set[str]: Set of gene names\n    \"\"\"\n    if resistanceCatalogue:\n        if resistanceGenesOnly:\n            resistanceGenes = set(resistanceCatalogue.catalogue.genes)\n            # Catch multi/epistasis rules which might not have specific instances\n            multis = set()\n            for _, rule in resistanceCatalogue.catalogue.rules.iterrows():\n                if rule[\"MUTATION_TYPE\"] in [\"MULTI\", \"EPISTASIS\"]:\n                    mutations = rule[\"MUTATION\"]\n                    for mut in mutations.split(\"&amp;\"):\n                        multis.add(mut.split(\"@\")[0])\n            resistanceGenes = resistanceGenes.union(multis)\n        else:\n            resistanceGenes = set(sample.gene_names)\n\n        return sample.genes_with_mutations.intersection(resistanceGenes)\n\n    else:\n        # No catalogue, so just stick to genes in the sample\n        return sample.genes\n</code></pre>"},{"location":"reference/gnomonicus_lib/#gnomonicus_lib.getMutations","title":"<code>getMutations(mutations_df, catalogue, reference)</code>","text":"<p>Get all of the mutations (including multi-mutations) from the mutations df Multi-mutations currently only exist within the converted WHO catalogue, and are a highly specific combination     of mutations which must all be present for a single resistance value.</p> <p>Parameters:</p> Name Type Description Default <code>mutations_df</code> <code>DataFrame</code> <p>Mutations dataframe</p> required <code>catalogue</code> <code>ResistanceCatalogue</code> <p>The resistance catalogue. Used to find which multi-mutations we care about</p> required <code>reference</code> <code>Genome</code> <p>Reference genome object. Used for checking if mutations are in coding regions</p> required <p>Returns:</p> Type Description <code>List[Tuple[str | None, str]]</code> <p>List[Tuple[str | None, str]]: List of [gene, mutation] or in the case of multi-mutations, [None, multi-mutation]</p> Source code in <code>gnomonicus/gnomonicus_lib.py</code> <pre><code>def getMutations(\n    mutations_df: pd.DataFrame | None,\n    catalogue: piezo.ResistanceCatalogue,\n    reference: grumpy.Genome,\n) -&gt; List[Tuple[str | None, str]]:\n    \"\"\"Get all of the mutations (including multi-mutations) from the mutations df\n    Multi-mutations currently only exist within the converted WHO catalogue, and are a highly specific combination\n        of mutations which must all be present for a single resistance value.\n\n    Args:\n        mutations_df (pd.DataFrame): Mutations dataframe\n        catalogue (piezo.ResistanceCatalogue): The resistance catalogue. Used to find which multi-mutations we care about\n        reference (grumpy.Genome): Reference genome object. Used for checking if mutations are in coding regions\n\n    Returns:\n        List[Tuple[str | None, str]]: List of [gene, mutation] or in the case of multi-mutations, [None, multi-mutation]\n    \"\"\"\n    if mutations_df is None:\n        return []\n    mutations: List[Tuple[str | None, str]] = list(\n        zip(mutations_df[\"gene\"], mutations_df[\"mutation\"])\n    )\n    # Grab the multi-mutations from the catalogue\n    # By doing this, we can check a fixed sample space rather than every permutation of the mutations\n    # This makes the problem tractable, but does not address a possible issue with multi-mutations not encapsulating full codons\n    multis = set(\n        catalogue.catalogue.rules[\n            catalogue.catalogue.rules[\"MUTATION_TYPE\"] == \"MULTI\"\n        ][\"MUTATION\"]\n    )\n    if len(multis) &gt; 0:\n        # We have a catalogue including multi rules, so check if any of these are present in the mutations\n        mutations = subset_multis(multis, mutations)\n\n    # Check if the catalogue supports large deletions\n    if \"GENE\" in set(catalogue.catalogue.rules[\"MUTATION_AFFECTS\"]):\n        large_dels = True\n    else:\n        large_dels = False\n\n    # Filtering out *just* nucleotide changes for cases of synon mutations\n    # The important part of these should have already been found by multi-mutations\n    fixed = []\n    for gene, mutation in mutations:\n        if gene is not None and reference.get_gene(gene).coding:\n            # Codes protein so check for nucleotide changes\n            nucleotide = re.compile(\n                r\"\"\"\n                [acgtzx][0-9]+[acgtzx]\n                \"\"\",\n                re.VERBOSE,\n            )\n            if nucleotide.fullmatch(mutation):\n                # Is a nucleotide (non-promoter) mutation in a coding gene\n                # So skip it as it may cause prediction problems\n                continue\n        # Remove large dels if not supported\n        if not large_dels:\n            # Check if this is a large del\n            large = re.compile(\n                r\"\"\"\n                del_(1\\.0)|(0\\.[0-9][0-9]?[0-9]?)\n                \"\"\",\n                re.VERBOSE,\n            )\n            if large.fullmatch(mutation):\n                continue\n        fixed.append((gene, mutation))\n    return sorted(fixed, key=lambda x: \"\".join([str(i) for i in x]))\n</code></pre>"},{"location":"reference/gnomonicus_lib/#gnomonicus_lib.get_minority_population_type","title":"<code>get_minority_population_type(catalogue)</code>","text":"<p>Figure out if a catalogue uses FRS or COV. If neither or both, default to FRS</p> <p>Parameters:</p> Name Type Description Default <code>catalogue</code> <code>ResistanceCatalogue | None</code> <p>Catalogue</p> required <p>Returns:</p> Type Description <code>MinorType</code> <p>grumpy.MinorType: Enum for FRS or COV respectively</p> Source code in <code>gnomonicus/gnomonicus_lib.py</code> <pre><code>def get_minority_population_type(\n    catalogue: piezo.ResistanceCatalogue | None,\n) -&gt; grumpy.MinorType:\n    \"\"\"Figure out if a catalogue uses FRS or COV. If neither or both, default to FRS\n\n    Args:\n        catalogue (piezo.ResistanceCatalogue | None): Catalogue\n\n    Returns:\n        grumpy.MinorType: Enum for FRS or COV respectively\n    \"\"\"\n    if catalogue is None:\n        # Nothing given, so default to FRS\n        return grumpy.MinorType.FRS\n    frs = 0\n    cov = 0\n    for minor in catalogue.catalogue.rules[\"MINOR\"]:\n        for m in minor.split(\",\"):\n            if m:\n                m = float(m)\n                assert m &gt; 0, f\"Minor populations must be positive: {m}\"\n                if m &lt; 1:\n                    # FRS\n                    frs += 1\n                else:\n                    # COV\n                    cov += 1\n    # We have just COV\n    if cov &gt; 0 and frs == 0:\n        return grumpy.MinorType.COV\n    # We have anything else\n    return grumpy.MinorType.FRS\n</code></pre>"},{"location":"reference/gnomonicus_lib/#gnomonicus_lib.parse_grumpy_evidence","title":"<code>parse_grumpy_evidence(evidence)</code>","text":"<p>Parse the grumpy evidence into a dictionary for JSON.</p> <p>As rust doesn't have multi-type hashmaps, we need to convert all values from strings Should just be parsing ints and floats</p> <p>Parameters:</p> Name Type Description Default <code>evidence</code> <code>VCFRow</code> <p>Evidence from the VCF</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Parsed evidence</p> Source code in <code>gnomonicus/gnomonicus_lib.py</code> <pre><code>def parse_grumpy_evidence(evidence: grumpy.VCFRow) -&gt; dict:\n    \"\"\"Parse the grumpy evidence into a dictionary for JSON.\n\n    As rust doesn't have multi-type hashmaps, we need to convert all values from strings\n    Should just be parsing ints and floats\n\n    Args:\n        evidence (grumpy.VCFRow): Evidence from the VCF\n\n    Returns:\n        dict: Parsed evidence\n    \"\"\"\n    ev = {}\n    for key, value in evidence.fields.items():\n        item: list[int | float | None] | int | float | None = []\n        if key == \"GT\":\n            # Special case here as we need to split the string and parse int/Nones\n            gt = value[0].split(\"/\")\n            item = [int(g) if g[0] != \".\" else None for g in gt]\n        elif key == \"DP\":\n            # Single value expected here too (most of the time)\n            if len(value) == 1:\n                # Odd edge cases around types though\n                if value[0] == \".\":\n                    item = None\n                else:\n                    try:\n                        item = int(value[0])\n                    except ValueError:\n                        item = float(value[0])\n            else:\n                item = [int(v) for v in value]\n        else:\n            if item is None or isinstance(item, int) or isinstance(item, float):\n                # Should never happen but appease mypy\n                continue\n            for v in value:\n                # Use duck typing to determine if it's a float or int\n                try:\n                    item.append(int(v))\n                except ValueError:\n                    try:\n                        item.append(float(v))\n                    except ValueError:\n                        item.append(v)\n        ev[key] = item\n    for key, val in ev.items():\n        if isinstance(val, list) and len(val) == 1:\n            # Unpack single values as they probably shouldn't be lists\n            ev[key] = val[0]\n    # We also want to add back in some of the VCF items which aren't in the fields dict\n    ev[\"POS\"] = evidence.position\n    ev[\"REF\"] = evidence.reference\n    ev[\"ALTS\"] = evidence.alternative\n    return ev\n</code></pre>"},{"location":"reference/gnomonicus_lib/#gnomonicus_lib.populateEffects","title":"<code>populateEffects(outputDir, resistanceCatalogue, mutations, vcfStem, make_csv, make_prediction_csv, reference, make_mutations_csv=False, append=False)</code>","text":"<p>Populate and save the effects DataFrame as a CSV</p> <p>Parameters:</p> Name Type Description Default <code>outputDir</code> <code>str</code> <p>Path to the directory to save the CSV</p> required <code>resistanceCatalogue</code> <code>ResistanceCatalogue</code> <p>Resistance catalogue for predictions</p> required <code>mutations</code> <code>DataFrame</code> <p>Mutations dataframe</p> required <code>vcfStem</code> <code>str</code> <p>The basename of the given VCF - used as the sample name</p> required <code>make_csv</code> <code>bool</code> <p>Whether to write the CSV of the dataframe</p> required <code>make_prediction_csv</code> <code>bool</code> <p>Whether to write the CSV of the antibiogram</p> required <code>reference</code> <code>Genome | None</code> <p>Reference genome. Defaults to None.</p> required <code>make_mutations_csv</code> <code>bool</code> <p>Whether to write the mutations CSV to disk with new mutations. Defaults to False.</p> <code>False</code> <code>append</code> <code>bool</code> <p>Whether to append data to an existing df at the location (if existing).</p> <code>False</code> <p>Raises:</p> Type Description <code>InvalidMutationException</code> <p>Raised if an invalid mutation is detected</p> <p>Returns:</p> Type Description <code>(DataFrame, dict)</code> <p>( DataFrame containing the effects data, A metadata dictionary mapping drugs to their predictions, DataFrame containing the mutations data</p> <code>Tuple[DataFrame, Dict, DataFrame] | None</code> <p>)</p> Source code in <code>gnomonicus/gnomonicus_lib.py</code> <pre><code>def populateEffects(\n    outputDir: str,\n    resistanceCatalogue: piezo.ResistanceCatalogue,\n    mutations: pd.DataFrame,\n    vcfStem: str,\n    make_csv: bool,\n    make_prediction_csv: bool,\n    reference: grumpy.Genome,\n    make_mutations_csv: bool = False,\n    append: bool = False,\n) -&gt; Tuple[pd.DataFrame, Dict, pd.DataFrame] | None:\n    \"\"\"Populate and save the effects DataFrame as a CSV\n\n    Args:\n        outputDir (str): Path to the directory to save the CSV\n        resistanceCatalogue (piezo.ResistanceCatalogue): Resistance catalogue for predictions\n        mutations (pd.DataFrame): Mutations dataframe\n        vcfStem (str): The basename of the given VCF - used as the sample name\n        make_csv (bool): Whether to write the CSV of the dataframe\n        make_prediction_csv (bool): Whether to write the CSV of the antibiogram\n        reference (grumpy.Genome | None, optional): Reference genome. Defaults to None.\n        make_mutations_csv (bool, optional): Whether to write the mutations CSV to disk with new mutations. Defaults to False.\n        append (bool, optional): Whether to append data to an existing df at the location (if existing).\n\n    Raises:\n        InvalidMutationException: Raised if an invalid mutation is detected\n\n    Returns:\n        (pd.DataFrame, dict): (\n            DataFrame containing the effects data,\n            A metadata dictionary mapping drugs to their predictions,\n            DataFrame containing the mutations data\n        )\n    \"\"\"\n    if resistanceCatalogue is None:\n        logging.debug(\"Catalogue was None, skipping effects and predictions generation\")\n        return None\n    # Assume wildtype behaviour unless otherwise specified\n    phenotype = {drug: \"S\" for drug in resistanceCatalogue.catalogue.drugs}\n\n    effects = {}\n    effectsCounter = 0\n\n    # Default prediction values are RFUS but use piezo catalogue's values if existing\n    values = resistanceCatalogue.catalogue.values\n\n    # only try and build an effects table if there are mutations\n    sample_mutations = getMutations(mutations, resistanceCatalogue, reference)\n    for gene, mutation in tqdm(sample_mutations):\n        # Ensure its a valid mutation\n        # if gene is not None and not referenceGenes[gene].valid_variant(mutation):\n        #     logging.error(f\"Not a valid mutation {gene}@{mutation}\")\n        #     raise InvalidMutationException(gene, mutation)\n\n        # Get the prediction\n        if gene is not None:\n            prediction = resistanceCatalogue.predict(\n                gene + \"@\" + mutation, show_evidence=True\n            )\n        else:\n            # This is a multi-mutation so is already of required format\n            prediction = resistanceCatalogue.predict(mutation, show_evidence=True)\n\n        # If the prediction is interesting, iter through drugs to find predictions\n        if prediction != \"S\" and not isinstance(prediction, str):\n            for drug in prediction.keys():\n                drug_pred = prediction[drug]\n                if isinstance(drug_pred, str):\n                    # This shouldn't happen because we're showing evidence\n                    # Adding to appease mypy...\n                    pred: str = drug_pred\n                    evidence: Dict = {}\n                else:\n                    pred, evidence = drug_pred\n                # Prioritise values based on order within the values list\n                if values.index(pred) &lt; values.index(phenotype[drug]):\n                    # The prediction is closer to the start of the values list, so should take priority\n                    phenotype[drug] = pred\n\n                # Add to the dict\n                effects[effectsCounter] = [\n                    vcfStem,\n                    gene,\n                    mutation,\n                    resistanceCatalogue.catalogue.name,\n                    drug,\n                    pred,\n                    evidence,\n                ]\n                # Increment counter\n                effectsCounter += 1\n\n    # Check for epistasis rules (which ignore prediction heirarchy)\n    effectsCounter = epistasis(\n        sample_mutations,\n        resistanceCatalogue,\n        phenotype,\n        effects,\n        effectsCounter,\n        vcfStem,\n    )\n\n    # Build the DataFrame\n    effects_df = pd.DataFrame.from_dict(\n        effects,\n        orient=\"index\",\n        columns=[\n            \"uniqueid\",\n            \"gene\",\n            \"mutation\",\n            \"catalogue_name\",\n            \"drug\",\n            \"prediction\",\n            \"evidence\",\n        ],\n    )\n    effects_df = effects_df[\n        [\n            \"uniqueid\",\n            \"gene\",\n            \"mutation\",\n            \"drug\",\n            \"prediction\",\n            \"catalogue_name\",\n            \"evidence\",\n        ]\n    ]\n    effects_df[\"catalogue_version\"] = resistanceCatalogue.catalogue.version\n    effects_df[\"prediction_values\"] = \"\".join(resistanceCatalogue.catalogue.values)\n\n    # Save as CSV\n    if make_csv:\n        if append:\n            # Check to see if there's anything there already\n            try:\n                old_effects = pd.read_csv(\n                    os.path.join(outputDir, f\"{vcfStem}.effects.csv\")\n                )\n                effects_df = pd.concat([old_effects, effects_df])\n            except FileNotFoundError:\n                pass\n\n        effects_df.to_csv(\n            os.path.join(outputDir, f\"{vcfStem}.effects.csv\"), index=False\n        )\n\n    effects_df.reset_index(inplace=True)\n\n    if make_prediction_csv:\n        # We need to construct a simple table here\n        predictions = [phenotype[drug] for drug in resistanceCatalogue.catalogue.drugs]\n        vals = {\n            \"uniqueid\": vcfStem,\n            \"drug\": resistanceCatalogue.catalogue.drugs,\n            \"prediction\": predictions,\n            \"catalogue_name\": resistanceCatalogue.catalogue.name,\n            \"catalogue_version\": resistanceCatalogue.catalogue.version,\n            \"catalogue_values\": \"\".join(resistanceCatalogue.catalogue.values),\n        }\n        predictions_df = pd.DataFrame(vals)\n        if append:\n            # Check to see if there's anything there already\n            try:\n                old_predictions = pd.read_csv(\n                    os.path.join(outputDir, f\"{vcfStem}.predictions.csv\")\n                )\n                predictions_df = pd.concat([old_predictions, predictions_df])\n            except FileNotFoundError:\n                pass\n        predictions_df.to_csv(\n            os.path.join(outputDir, f\"{vcfStem}.predictions.csv\"), index=False\n        )\n    if len(effects) == 0:\n        # We have no effects to report so populate empty df\n        effects_df = pd.DataFrame.from_dict(effects)\n\n    # Return  the metadata dict to log later\n    return (\n        effects_df,\n        {drug: phenotype[drug] for drug in resistanceCatalogue.catalogue.drugs},\n        mutations,\n    )\n</code></pre>"},{"location":"reference/gnomonicus_lib/#gnomonicus_lib.populateMutations","title":"<code>populateMutations(vcfStem, outputDir, genome_diff, reference, sample, resistanceCatalogue, make_csv, resistanceGenesOnly)</code>","text":"<p>Popuate and save the mutations DataFrame as a CSV, then return it for use in predictions</p> <p>Parameters:</p> Name Type Description Default <code>vcfStem</code> <code>str</code> <p>The stem of the filename of the VCF file. Used as a uniqueID</p> required <code>outputDir</code> <code>str</code> <p>Path to the desired output directory</p> required <code>genome_diff</code> <code>GenomeDifference</code> <p>GenomeDifference object between reference and this sample</p> required <code>reference</code> <code>Genome</code> <p>Reference genome</p> required <code>sample</code> <code>Genome</code> <p>Sample genome</p> required <code>resistanceCatalogue</code> <code>ResistanceCatalogue</code> <p>Resistance catalogue (used to find which genes to check)</p> required <code>make_csv</code> <code>bool</code> <p>Whether to write the CSV of the dataframe</p> required <code>resistanceGenesOnly</code> <code>bool</code> <p>Whether to use just genes present in the resistance catalogue</p> required <p>Raises:</p> Type Description <code>MissingFieldException</code> <p>Raised when the mutations DataFrame does not contain the required fields</p> <p>Returns:</p> Type Description <code>DataFrame | None</code> <p>pd.DataFrame: The mutations DataFrame</p> Source code in <code>gnomonicus/gnomonicus_lib.py</code> <pre><code>def populateMutations(\n    vcfStem: str,\n    outputDir: str,\n    genome_diff: grumpy.GenomeDifference,\n    reference: grumpy.Genome,\n    sample: grumpy.Genome,\n    resistanceCatalogue: piezo.ResistanceCatalogue,\n    make_csv: bool,\n    resistanceGenesOnly: bool,\n) -&gt; pd.DataFrame | None:\n    \"\"\"Popuate and save the mutations DataFrame as a CSV, then return it for use in predictions\n\n    Args:\n        vcfStem (str): The stem of the filename of the VCF file. Used as a uniqueID\n        outputDir (str): Path to the desired output directory\n        genome_diff (grumpy.GenomeDifference): GenomeDifference object between reference and this sample\n        reference (grumpy.Genome): Reference genome\n        sample (grumpy.Genome): Sample genome\n        resistanceCatalogue (piezo.ResistanceCatalogue): Resistance catalogue (used to find which genes to check)\n        make_csv (bool): Whether to write the CSV of the dataframe\n        resistanceGenesOnly (bool): Whether to use just genes present in the resistance catalogue\n\n    Raises:\n        MissingFieldException: Raised when the mutations DataFrame does not contain the required fields\n\n    Returns:\n        pd.DataFrame: The mutations DataFrame\n    \"\"\"\n    genesWithMutations = getGenes(sample, resistanceCatalogue, resistanceGenesOnly)\n\n    # Iter resistance genes with variation to produce gene level mutations - concating into a single dataframe\n    mutations: dict[str, list] = {\n        \"gene\": [],\n        \"mutation\": [],\n        \"ref\": [],\n        \"alt\": [],\n        \"nucleotide_number\": [],\n        \"nucleotide_index\": [],\n        \"gene_position\": [],\n        \"codes_protein\": [],\n        \"indel_length\": [],\n        \"indel_nucleotides\": [],\n        \"amino_acid_number\": [],\n        \"amino_acid_sequence\": [],\n        \"number_nucleotide_changes\": [],\n    }\n    for gene_name in sorted(genesWithMutations):\n        gene_diff = grumpy.GeneDifference(\n            reference.get_gene(gene_name),\n            sample.get_gene(gene_name),\n            get_minority_population_type(resistanceCatalogue),\n        )\n        for mutation in gene_diff.mutations:\n            mutations[\"gene\"].append(gene_name)\n            mutations[\"mutation\"].append(mutation.mutation)\n            mutations[\"ref\"].append(mutation.ref_nucleotides)\n            mutations[\"alt\"].append(mutation.alt_nucleotides)\n            mutations[\"nucleotide_number\"].append(mutation.nucleotide_number)\n            mutations[\"nucleotide_index\"].append(mutation.nucleotide_index)\n            mutations[\"gene_position\"].append(mutation.gene_position)\n            mutations[\"codes_protein\"].append(mutation.codes_protein)\n            mutations[\"indel_length\"].append(mutation.indel_length)\n            mutations[\"indel_nucleotides\"].append(mutation.indel_nucleotides)\n            mutations[\"amino_acid_number\"].append(mutation.amino_acid_number)\n            mutations[\"amino_acid_sequence\"].append(mutation.amino_acid_sequence)\n            mutations[\"number_nucleotide_changes\"].append(\n                count_nucleotide_changes(\n                    mutation.ref_nucleotides, mutation.alt_nucleotides\n                )\n            )\n        for mutation in gene_diff.minor_mutations:\n            mutations[\"gene\"].append(gene_name)\n            mutations[\"mutation\"].append(mutation.mutation)\n            mutations[\"ref\"].append(mutation.ref_nucleotides)\n            mutations[\"alt\"].append(mutation.alt_nucleotides)\n            mutations[\"nucleotide_number\"].append(mutation.nucleotide_number)\n            mutations[\"nucleotide_index\"].append(mutation.nucleotide_index)\n            mutations[\"gene_position\"].append(mutation.gene_position)\n            mutations[\"codes_protein\"].append(mutation.codes_protein)\n            mutations[\"indel_length\"].append(mutation.indel_length)\n            mutations[\"indel_nucleotides\"].append(mutation.indel_nucleotides)\n            mutations[\"amino_acid_number\"].append(mutation.amino_acid_number)\n            mutations[\"amino_acid_sequence\"].append(mutation.amino_acid_sequence)\n            mutations[\"number_nucleotide_changes\"].append(\n                count_nucleotide_changes(\n                    mutation.ref_nucleotides, mutation.alt_nucleotides\n                )\n            )\n\n    # Ensure correct datatypes\n    mutations_df = pd.DataFrame(mutations).astype(\n        {\n            \"mutation\": \"str\",\n            \"gene\": \"str\",\n            \"nucleotide_number\": \"Int64\",\n            \"nucleotide_index\": \"Int64\",\n            \"gene_position\": \"Int64\",\n            \"alt\": \"str\",\n            \"ref\": \"str\",\n            \"codes_protein\": \"bool\",\n            \"indel_length\": \"Int64\",\n            \"indel_nucleotides\": \"str\",\n            \"amino_acid_number\": \"Int64\",\n            \"amino_acid_sequence\": \"str\",\n        }\n    )\n    # If there were mutations, write them to a CSV\n\n    # Add VCF stem as the uniqueID\n    mutations_df[\"uniqueid\"] = vcfStem\n\n    if make_csv:\n        write_mutations_csv(\n            mutations_df, os.path.join(outputDir, f\"{vcfStem}.mutations.csv\")\n        )\n\n    return mutations_df\n</code></pre>"},{"location":"reference/gnomonicus_lib/#gnomonicus_lib.populateVariants","title":"<code>populateVariants(vcfStem, outputDir, diff, make_csv, resistanceGenesOnly, sample, catalogue=None)</code>","text":"<p>Populate and save the variants DataFrame as a CSV</p> <p>Parameters:</p> Name Type Description Default <code>vcfStem</code> <code>str</code> <p>The stem of the filename for the VCF file. Used as a uniqueID</p> required <code>outputDir</code> <code>str</code> <p>Path to the desired output directory</p> required <code>diff</code> <code>GenomeDifference</code> <p>GenomeDifference object between reference and the sample</p> required <code>make_csv</code> <code>bool</code> <p>Whether to write the CSV of the dataframe</p> required <code>resistanceGenesOnly</code> <code>bool</code> <p>Whether to use just genes present in the resistance catalogue</p> required <code>sample</code> <code>Genome</code> <p>Sample genome object</p> required <code>catalogue</code> <code>ResistanceCatalogue | None</code> <p>Catalogue for determining FRS or COV for minority populations. If None is given, FRS is assumed. Defaults to None</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: DataFrame of the variants</p> Source code in <code>gnomonicus/gnomonicus_lib.py</code> <pre><code>def populateVariants(\n    vcfStem: str,\n    outputDir: str,\n    diff: grumpy.GenomeDifference,\n    make_csv: bool,\n    resistanceGenesOnly: bool,\n    sample: grumpy.Genome,\n    catalogue: piezo.ResistanceCatalogue | None = None,\n) -&gt; pd.DataFrame:\n    \"\"\"Populate and save the variants DataFrame as a CSV\n\n    Args:\n        vcfStem (str): The stem of the filename for the VCF file. Used as a uniqueID\n        outputDir (str): Path to the desired output directory\n        diff (grumpy.GenomeDifference): GenomeDifference object between reference and the sample\n        make_csv (bool): Whether to write the CSV of the dataframe\n        resistanceGenesOnly (bool): Whether to use just genes present in the resistance catalogue\n        sample (grumpy.Genome): Sample genome object\n        catalogue (piezo.ResistanceCatalogue | None, optional): Catalogue for determining FRS or COV for minority populations. If None is given, FRS is assumed. Defaults to None\n\n    Returns:\n        pd.DataFrame: DataFrame of the variants\n    \"\"\"\n    # Populate variants table directly from GenomeDifference\n    vals: dict[str, list] = {\n        \"variant\": [],\n        \"nucleotide_index\": [],\n        \"indel_length\": [],\n        \"indel_nucleotides\": [],\n        \"vcf_evidence\": [],\n        \"vcf_idx\": [],\n        \"gene\": [],\n        \"gene_position\": [],\n        \"codon_idx\": [],\n    }\n    for variant in diff.variants:\n        vals[\"variant\"].append(variant.variant)\n        vals[\"nucleotide_index\"].append(variant.nucleotide_index)\n        vals[\"indel_length\"].append(variant.indel_length)\n        vals[\"indel_nucleotides\"].append(variant.indel_nucleotides)\n        vals[\"vcf_evidence\"].append(\n            json.dumps(parse_grumpy_evidence(sample.get_vcf_row(variant.evidence)))\n        )\n        vals[\"vcf_idx\"].append(variant.vcf_idx)\n        vals[\"gene\"].append(variant.gene_name)\n        vals[\"gene_position\"].append(variant.gene_position)\n        vals[\"codon_idx\"].append(variant.codon_idx)\n\n    for variant in diff.minor_variants:\n        vals[\"variant\"].append(variant.variant)\n        vals[\"nucleotide_index\"].append(variant.nucleotide_index)\n        vals[\"indel_length\"].append(variant.indel_length)\n        vals[\"indel_nucleotides\"].append(variant.indel_nucleotides)\n        vals[\"vcf_evidence\"].append(\n            json.dumps(parse_grumpy_evidence(sample.get_vcf_row(variant.evidence)))\n        )\n        vals[\"vcf_idx\"].append(variant.vcf_idx)\n        vals[\"gene\"].append(variant.gene_name)\n        vals[\"gene_position\"].append(variant.gene_position)\n        vals[\"codon_idx\"].append(variant.codon_idx)\n\n    # Use of Int64 rather than int is required here as pandas doesn't allow mixed int/None\n    variants = pd.DataFrame(vals).astype(\n        {\n            \"vcf_evidence\": \"object\",\n            \"nucleotide_index\": \"Int64\",\n            \"indel_length\": \"Int64\",\n            \"vcf_idx\": \"Int64\",\n            \"gene_position\": \"Int64\",\n            \"codon_idx\": \"Int64\",\n        }\n    )\n\n    if catalogue is not None:\n        # Figure out if we want to keep all of the variants\n        genes = getGenes(sample, catalogue, resistanceGenesOnly)\n        to_drop = []\n        for idx, row in variants.iterrows():\n            if row[\"gene\"] not in genes:\n                # Not a variant we're interested in, so remove\n                to_drop.append(idx)\n\n        variants.drop(index=to_drop, inplace=True)\n\n    # Add unique ID to each record\n    variants[\"uniqueid\"] = vcfStem\n\n    variants = variants[\n        [\n            \"uniqueid\",\n            \"variant\",\n            \"gene\",\n            \"gene_position\",\n            \"codon_idx\",\n            \"nucleotide_index\",\n            \"indel_length\",\n            \"indel_nucleotides\",\n            \"vcf_evidence\",\n            \"vcf_idx\",\n        ]\n    ]\n    variants = variants.drop_duplicates()\n    if make_csv:\n        # Save CSV\n        variants.to_csv(\n            os.path.join(outputDir, f\"{vcfStem}.variants.csv\"),\n            header=True,\n            index=False,\n        )\n    variants.reset_index(inplace=True)\n    return variants\n</code></pre>"},{"location":"reference/gnomonicus_lib/#gnomonicus_lib.saveJSON","title":"<code>saveJSON(variants, mutations, effects, phenotypes, path, guid, catalogue, gnomonicusVersion, time_taken, reference, vcf_path, reference_path, catalogue_path)</code>","text":"<p>Create and save a single JSON output file for use within GPAS. JSON structure: {     'meta': {         'status': If this has succeeded or not (but this isn't created in cases it doesn't succeed),         'workflow_name': 'gnomonicus',         'workflow_task': 'resistance_prediction' or 'virulenece prediction',         'workflow_version': gnomonicus.version,         'time_taken': Time this step took,         'UTC_timestamp': Timestamp for the end of this run,         'catalogue_type': discrete_values or mic,         'catalogue_name': Name of catalogue,         'catalogue_version': Version of the catalogue,         'reference': Name of the reference genome used,         'catalogue_file': Path to the catalogue,         'reference_file': Path to the reference file,         'vcf_file': Path to the VCF file     },     ?'errors': {         :      }     'data': {         'variants': [             {                 'variant': Genome level variant in GARC,                 'nucleotide_index': Genome index of variant,                 'gene_name': Name of the gene this variant affects (if applicable),                 'gene_position': Gene position which this variant affects. Nucleotide number if non coding, codon indx if coding (if applicable),                 'codon_idx': Index of the base within the corresponding codon this affects (if applicable),                 'vcf_evidence': Parsed VCF row,                 'vcf_idx': Which part of the VCF row to look at for this call             }, ...         ],         ?'mutations': [             {                 'mutation': Gene level mutation in GARC,                 'gene': Gene name,                 'gene_position': Position within the gene. Amino acid or nucleotide index depending on which is appropriate,                 'vcf_evidence': Parsed VCF row,                 'ref': Ref base(s),                 'alt': Alt base(s)             }         ],         ?'effects': {             Drug name: [                 {                     'gene': Gene name of the mutation,                     'mutation': Gene level mutation in GARC,                     'prediction': Prediction caused by this mutation,                     'evidence': Evidence to support this prediction. Currently placeholder                 }, ...,                 {                     'phenotype': Resultant prediction for this drug based on prediciton heirarchy                 }             ], ...         }         ?'antibiogram': {              :  essentially jsondata         }     } } Where fields with a preceeding '?' are not always present depending on data <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the directory where the variant/mutation/effect CSV files are saved. Also the output dir for this.</p> required <code>guid</code> <code>str</code> <p>Sample GUID</p> required <code>catalogue</code> <code>ResistanceCatalogue</code> <p>Catalogue used</p> required <code>gnomonicusVersion</code> <code>str</code> <p>Semantic versioning string for the gnomonicus module. Can be accessed by <code>gnomonicus.__version__</code></p> required <code>time_taken</code> <code>float</code> <p>Number of seconds taken to run this.</p> required <code>reference</code> <code>Genome</code> <p>Reference genome object</p> required <code>vcf_path</code> <code>str</code> <p>Path to the VCF file used for this run</p> required <code>reference_path</code> <code>str</code> <p>Path to the reference genome used for this run</p> required <code>catalogue_path</code> <code>str</code> <p>Path to the catalogue used for this run</p> required <code>minor_errors</code> <code>dict</code> <p>Mapping of gene name --&gt; stack trace of any errors occurring when parsing minor mutations</p> required Source code in <code>gnomonicus/gnomonicus_lib.py</code> <pre><code>def saveJSON(\n    variants,\n    mutations,\n    effects,\n    phenotypes: dict[str, str],\n    path: str,\n    guid: str,\n    catalogue: piezo.ResistanceCatalogue,\n    gnomonicusVersion: str,\n    time_taken: float,\n    reference: grumpy.Genome,\n    vcf_path: str,\n    reference_path: str,\n    catalogue_path: str,\n) -&gt; None:\n    \"\"\"Create and save a single JSON output file for use within GPAS. JSON structure:\n    {\n        'meta': {\n            'status': If this has succeeded or not (but this isn't created in cases it doesn't succeed),\n            'workflow_name': 'gnomonicus',\n            'workflow_task': 'resistance_prediction' or 'virulenece prediction',\n            'workflow_version': gnomonicus.__version__,\n            'time_taken': Time this step took,\n            'UTC_timestamp': Timestamp for the end of this run,\n            'catalogue_type': discrete_values or mic,\n            'catalogue_name': Name of catalogue,\n            'catalogue_version': Version of the catalogue,\n            'reference': Name of the reference genome used,\n            'catalogue_file': Path to the catalogue,\n            'reference_file': Path to the reference file,\n            'vcf_file': Path to the VCF file\n        },\n        ?'errors': {\n            &lt;gene name&gt;: &lt;stack trace&gt;\n        }\n        'data': {\n            'variants': [\n                {\n                    'variant': Genome level variant in GARC,\n                    'nucleotide_index': Genome index of variant,\n                    'gene_name': Name of the gene this variant affects (if applicable),\n                    'gene_position': Gene position which this variant affects. Nucleotide number if non coding, codon indx if coding (if applicable),\n                    'codon_idx': Index of the base within the corresponding codon this affects (if applicable),\n                    'vcf_evidence': Parsed VCF row,\n                    'vcf_idx': Which part of the VCF row to look at for this call\n                }, ...\n            ],\n            ?'mutations': [\n                {\n                    'mutation': Gene level mutation in GARC,\n                    'gene': Gene name,\n                    'gene_position': Position within the gene. Amino acid or nucleotide index depending on which is appropriate,\n                    'vcf_evidence': Parsed VCF row,\n                    'ref': Ref base(s),\n                    'alt': Alt base(s)\n                }\n            ],\n            ?'effects': {\n                Drug name: [\n                    {\n                        'gene': Gene name of the mutation,\n                        'mutation': Gene level mutation in GARC,\n                        'prediction': Prediction caused by this mutation,\n                        'evidence': Evidence to support this prediction. Currently placeholder\n                    }, ...,\n                    {\n                        'phenotype': Resultant prediction for this drug based on prediciton heirarchy\n                    }\n                ], ...\n            }\n            ?'antibiogram': {\n                &lt;drug&gt; : &lt;prediction&gt; essentially json[data][effects][&lt;drug&gt;][phenotype]\n            }\n        }\n    }\n    Where fields with a preceeding '?' are not always present depending on data\n\n    Args:\n        path (str): Path to the directory where the variant/mutation/effect CSV files are saved. Also the output dir for this.\n        guid (str): Sample GUID\n        catalogue (piezo.ResistanceCatalogue): Catalogue used\n        gnomonicusVersion (str): Semantic versioning string for the gnomonicus module. Can be accessed by `gnomonicus.__version__`\n        time_taken (float): Number of seconds taken to run this.\n        reference (grumpy.Genome): Reference genome object\n        vcf_path (str): Path to the VCF file used for this run\n        reference_path (str): Path to the reference genome used for this run\n        catalogue_path (str): Path to the catalogue used for this run\n        minor_errors (dict): Mapping of gene name --&gt; stack trace of any errors occurring when parsing minor mutations\n    \"\"\"\n    # Define some metadata for the json\n    meta = OrderedDict(\n        {\n            \"status\": \"success\",\n            \"workflow_name\": \"gnomonicus\",\n            \"workflow_version\": gnomonicusVersion,  # gnomonicus version used\n            \"workflow_task\": \"resistance_prediction\",  # TODO: Update this when we know how to detect a virulence catalogue\n            \"guid\": guid,  # Sample GUID\n            \"UTC-datetime-completed\": datetime.datetime.utcnow().isoformat(),  # ISO datetime run\n            \"time_taken_s\": time_taken,\n            \"reference\": reference.name,\n            \"catalogue_file\": catalogue_path,\n            \"reference_file\": reference_path,\n            \"vcf_file\": vcf_path,\n        }\n    )\n    if catalogue is not None:\n        meta[\"catalogue_type\"] = \"\".join(catalogue.catalogue.values)\n        meta[\"catalogue_name\"] = catalogue.catalogue.name\n        meta[\"catalogue_version\"] = catalogue.catalogue.version\n    else:\n        meta[\"catalogue_type\"] = None\n        meta[\"catalogue_name\"] = None\n        meta[\"catalogue_version\"] = None\n\n    # Main data collection\n    data: Dict = OrderedDict()\n\n    # Antibigram field\n    data[\"antibiogram\"] = OrderedDict(\n        [(key, phenotypes[key]) for key in sorted(phenotypes.keys())]\n    )\n\n    # Variants field\n    _variants = []\n    for _, variant in variants.iterrows():\n        row = OrderedDict(\n            {\n                \"variant\": (\n                    variant[\"variant\"] if pd.notnull(variant[\"variant\"]) else None\n                ),\n                \"nucleotide_index\": (\n                    variant[\"nucleotide_index\"]\n                    if pd.notnull(variant[\"nucleotide_index\"])\n                    else None\n                ),\n                \"gene_name\": variant[\"gene\"] if pd.notnull(variant[\"gene\"]) else None,\n                \"gene_position\": (\n                    variant[\"gene_position\"]\n                    if pd.notnull(variant[\"gene_position\"])\n                    else None\n                ),\n                \"codon_idx\": (\n                    variant[\"codon_idx\"] if pd.notnull(variant[\"codon_idx\"]) else None\n                ),\n                \"vcf_evidence\": json.loads(variant[\"vcf_evidence\"]),\n                \"vcf_idx\": (\n                    variant[\"vcf_idx\"] if pd.notnull(variant[\"vcf_idx\"]) else None\n                ),\n            }\n        )\n        _variants.append(row)\n    _variants = sorted(\n        _variants,\n        key=lambda x: (\n            x[\"gene_name\"] or \"z\",\n            x[\"gene_position\"] or 0,\n            x[\"variant\"] or \"z\",\n        ),\n    )\n    data[\"variants\"] = _variants\n\n    # Depending on mutations/effects, populate\n    _mutations = []\n    if mutations is not None:\n        for _, mutation in mutations.iterrows():\n            row = OrderedDict(\n                {\n                    \"gene\": mutation[\"gene\"] if pd.notnull(mutation[\"gene\"]) else None,\n                    \"gene_position\": (\n                        mutation[\"gene_position\"]\n                        if pd.notnull(mutation[\"gene_position\"])\n                        else None\n                    ),\n                    \"mutation\": (\n                        mutation[\"mutation\"]\n                        if pd.notnull(mutation[\"mutation\"])\n                        else None\n                    ),\n                }\n            )\n            if mutation[\"mutation\"][0].isupper() or mutation[\"mutation\"][0] == \"!\":\n                # Only add codon ref/alt for AA changes\n                row[\"ref\"] = mutation[\"ref\"] if pd.notnull(mutation[\"ref\"]) else None\n                row[\"alt\"] = mutation[\"alt\"] if pd.notnull(mutation[\"alt\"]) else None\n            _mutations.append(row)\n\n    _mutations = sorted(\n        _mutations,\n        key=lambda x: (x[\"gene\"] or \"z\", x[\"gene_position\"] or 0),\n    )\n    data[\"mutations\"] = _mutations\n\n    _effects = defaultdict(list)\n    if effects is not None and len(effects) &gt; 0:\n        for _, effect in effects.iterrows():\n            prediction = OrderedDict(\n                {\n                    \"gene\": effect[\"gene\"] if pd.notnull(effect[\"gene\"]) else None,\n                    \"mutation\": (\n                        effect[\"mutation\"] if pd.notnull(effect[\"mutation\"]) else None\n                    ),\n                    \"prediction\": (\n                        effect[\"prediction\"]\n                        if pd.notnull(effect[\"prediction\"])\n                        else None\n                    ),\n                    \"evidence\": effect[\"evidence\"],\n                }\n            )\n            _effects[effect[\"drug\"]].append(prediction)\n\n    for drug in _effects.keys():\n        _effects[drug] = sorted(\n            _effects[drug],\n            key=lambda x: (x[\"gene\"] or \"z\", x[\"mutation\"] or \"z\"),\n        )\n        _effects[drug].append(OrderedDict({\"phenotype\": phenotypes[drug]}))\n\n    data[\"effects\"] = OrderedDict(\n        [(key, _effects[key]) for key in sorted(_effects.keys())]\n    )\n\n    # Convert fields to a list so it can be json serialised\n    with open(\n        os.path.join(path, f\"{guid}.gnomonicus-out.json\"), \"w\", encoding=\"utf-8\"\n    ) as f:\n        f.write(json.dumps({\"meta\": meta, \"data\": data}, indent=2))\n</code></pre>"},{"location":"reference/gnomonicus_lib/#gnomonicus_lib.subset_multis","title":"<code>subset_multis(multis, mutations_, just_joined=False)</code>","text":"<p>Given a list of multis, combine existing mutations to match them</p> <p>Parameters:</p> Name Type Description Default <code>multis</code> <code>set[str]</code> <p>Set of multi mutations</p> required <code>mutations_</code> <code>list[tuple[str | None, str]]</code> <p>mutations in</p> required <code>just_joined</code> <code>bool</code> <p>Whether to return all mutations or just joined multis. Defaults to False</p> <code>False</code> <p>Returns:</p> Type Description <code>list[tuple[str | None, str]]</code> <p>list[tuple[str|None, str]]: Multi-mutations which should hit catalogue rules</p> Source code in <code>gnomonicus/gnomonicus_lib.py</code> <pre><code>def subset_multis(\n    multis: set[str],\n    mutations_: list[tuple[str | None, str]],\n    just_joined: bool = False,\n) -&gt; list[tuple[str | None, str]]:\n    \"\"\"Given a list of multis, combine existing mutations to match them\n\n    Args:\n        multis (set[str]): Set of multi mutations\n        mutations_ (list[tuple[str | None, str]]): mutations in\n        just_joined (bool, optional): Whether to return all mutations or just joined multis. Defaults to False\n\n    Returns:\n        list[tuple[str|None, str]]: Multi-mutations which should hit catalogue rules\n    \"\"\"\n    mutations = [\n        (gene, mut, mut.split(\":\")[-1] if \":\" in mut else None)\n        for (gene, mut) in mutations_\n        if gene\n        if not None\n    ]\n    joined = set([gene + \"@\" + mut for (gene, mut, _) in mutations])\n    large_del_re = re.compile(\n        r\"\"\"\n        .*del_[01]\\.[0-9]+.*\n        \"\"\",\n        re.VERBOSE,\n    )\n    snp_re = re.compile(\n        r\"\"\"\n        [acgtxzA-Z!]-?[0-9]+[acgtxzA-Z!]\n    \"\"\",\n        re.VERBOSE,\n    )\n    early_stop_re = re.compile(\n        r\"\"\"\n        [A-Z!]-?[0-9]+!\n    \"\"\",\n        re.VERBOSE,\n    )\n    indel_re = re.compile(\n        r\"\"\"\n        -?[0-9]+_(ins|del|indel|mixed|fs)(_(([0-9]+)|([a-z]+)))?\n    \"\"\",\n        re.VERBOSE,\n    )\n\n    # Find these once so they aren't fetched on every iteration\n    existing_genes = set([gene for (gene, _, _) in mutations])\n    large_dels = [\n        (gene, mut, minor)\n        for (gene, mut, minor) in mutations\n        if large_del_re.fullmatch(mut)\n    ]\n    snps = [\n        (gene, mut, minor) for (gene, mut, minor) in mutations if snp_re.fullmatch(mut)\n    ]\n    early_stop = [\n        (gene, mut, minor)\n        for (gene, mut, minor) in mutations\n        if early_stop_re.fullmatch(mut)\n    ]\n    indels = [\n        (gene, mut, minor)\n        for (gene, mut, minor) in mutations\n        if indel_re.fullmatch(mut)\n    ]\n\n    new_mutations: list[tuple[str | None, str]] = []\n    for multi in multis:\n        multi_match = []\n        check = True\n        if \"*\" in multi or \"?\" in multi or large_del_re.fullmatch(multi):\n            # We need to be a bit more cleaver here to avoid combinatorics ruining things\n            for mutation in multi.split(\"&amp;\"):\n                gene, mut = mutation.split(\"@\")\n                rule_is_minor = \":\" in mut\n                this_match = []\n                if gene not in existing_genes:\n                    # Gene doesn't exist in this sample, so skip\n                    check = False\n                if \"*\" in mutation:\n                    # A few cases here, wildcard or early-stop SNP, ins, del, indel, fs\n                    if \"?\" in mutation:\n                        # Wildcard-non-synon SNP so match any SNP in this gene\n                        if \"-\" in mutation:\n                            promoter = True\n                        else:\n                            promoter = False\n                        matched = False\n                        for g, m, minor in snps:\n                            if g == gene and (\n                                (minor is None and not rule_is_minor)\n                                or (minor is not None and rule_is_minor)\n                            ):\n                                if promoter and \"-\" in m:\n                                    matched = True\n                                    if minor is not None:\n                                        this_match.append(g + \"@\" + m + \":\" + minor)\n                                    else:\n                                        this_match.append(g + \"@\" + m)\n                                elif not promoter and \"-\" not in m:\n                                    matched = True\n                                    if minor is not None:\n                                        this_match.append(g + \"@\" + m + \":\" + minor)\n                                    else:\n                                        this_match.append(g + \"@\" + m)\n                        check = check and matched\n                    elif \"!\" in mutation:\n                        matched = False\n                        for g, m, minor in early_stop:\n                            if g == gene and (\n                                (minor is None and not rule_is_minor)\n                                or (minor is not None and rule_is_minor)\n                            ):\n                                matched = True\n                                if minor is not None:\n                                    this_match.append(g + \"@\" + m + \":\" + minor)\n                                else:\n                                    this_match.append(g + \"@\" + m)\n                        check = check and matched\n                    elif \"=\" in mutation:\n                        matched = False\n                        for g, m, minor in snps:\n                            if (\n                                g == gene\n                                and m[0] == m[-1]\n                                and (\n                                    (minor is None and not rule_is_minor)\n                                    or (minor is not None and rule_is_minor)\n                                )\n                            ):\n                                matched = True\n                                if minor is not None:\n                                    this_match.append(g + \"@\" + m + \":\" + minor)\n                                else:\n                                    this_match.append(g + \"@\" + m)\n                        check = check and matched\n                    else:\n                        # Wildcard indels never have associated numbers or bases (as that wouldn't make sense)\n                        # So check for matches\n                        matched = False\n                        if \"-\" in mutation:\n                            promoter = True\n                        else:\n                            promoter = False\n\n                        if \"ins\" in mutation or \"del\" in mutation:\n                            if \"ins\" in mutation:\n                                searching = \"ins\"\n                            else:\n                                searching = \"del\"\n                            for g, m, minor in indels:\n                                if g == gene and (\n                                    (minor is None and not rule_is_minor)\n                                    or (minor is not None and rule_is_minor)\n                                ):\n                                    if promoter and \"-\" not in m:\n                                        continue\n                                    elif not promoter and \"-\" in m:\n                                        continue\n                                    if searching in m:\n                                        matched = True\n                                        if minor is not None:\n                                            this_match.append(g + \"@\" + m + \":\" + minor)\n                                        else:\n                                            this_match.append(g + \"@\" + m)\n                        elif \"fs\" in mutation:\n                            # Bit more annoying here as we have to check if specific indels are framshifting\n                            for g, m, minor in indels:\n                                if g == gene and (\n                                    (minor is None and not rule_is_minor)\n                                    or (minor is not None and rule_is_minor)\n                                ):\n                                    # Don't need to check for promoters here as promoter framshift doesn't make sense\n                                    bases_in = m.split(\"_\")[-1]\n                                    if bases_in.isnumeric():\n                                        # Number of bases rather than actual bases\n                                        bases = int(bases_in)\n                                    else:\n                                        bases = len(bases_in)\n                                    if bases % 3 != 0:\n                                        matched = True\n                                        if minor is not None:\n                                            this_match.append(g + \"@\" + m + \":\" + minor)\n                                        else:\n                                            this_match.append(g + \"@\" + m)\n                        else:\n                            # Only mixed left\n                            for g, m, minor in indels:\n                                if g == gene and (\n                                    (minor is None and not rule_is_minor)\n                                    or (minor is not None and rule_is_minor)\n                                ):\n                                    if \"mixed\" in m:\n                                        matched = True\n                                        if minor is not None:\n                                            this_match.append(g + \"@\" + m + \":\" + minor)\n                                        else:\n                                            this_match.append(g + \"@\" + m)\n                        check = check and matched\n\n                elif \"?\" in mut:\n                    # Specific wildcard SNP, so match on everything except the alt\n                    mut = mut[:-1]\n                    for g, m, minor in snps:\n                        if (\n                            g == gene\n                            and m[:-1] == mut\n                            and (\n                                (minor is None and not rule_is_minor)\n                                or (minor is not None and rule_is_minor)\n                            )\n                        ):\n                            check = check and True\n                            if minor is not None:\n                                this_match.append(g + \"@\" + m + \":\" + minor)\n                            else:\n                                this_match.append(g + \"@\" + m)\n\n                elif large_del_re.fullmatch(mutation):\n                    for g, m, minor in large_dels:\n                        if g == gene and (\n                            (minor is None and not rule_is_minor)\n                            or (minor is not None and rule_is_minor)\n                        ):\n                            check = check and True\n                            if minor is not None:\n                                this_match.append(g + \"@\" + m + \":\" + minor)\n                            else:\n                                this_match.append(g + \"@\" + m)\n                else:\n                    # Exact part, so check for it's existance\n                    check = check and mutation in joined\n                    if check:\n                        # Exists, so add it to this multi\n                        this_match.append(mutation)\n\n                if check:\n                    multi_match.append(this_match)\n                else:\n                    # Give up at first hurdle\n                    break\n            if check:\n                # Add all if valid\n                partials = multi_match[0]\n                for item in multi_match[1:]:\n                    these_partials = []\n                    for mutation in item:\n                        this_partial = []\n                        for p in partials:\n                            this_partial.append(p + \"&amp;\" + mutation)\n                        these_partials += this_partial\n                    partials = these_partials\n\n                for p in partials:\n                    new_mutations.append((None, p))\n\n        else:\n            # Exact multi, so just check for existance\n            for mutation in multi.split(\"&amp;\"):\n                check = check and mutation in joined\n            if check:\n                # This exact multi mutation exists, so add it to the mutations list\n                new_mutations.append((None, multi))\n    if just_joined:\n        return new_mutations\n    return mutations_ + new_mutations\n</code></pre>"},{"location":"reference/gnomonicus_lib/#gnomonicus_lib.write_mutations_csv","title":"<code>write_mutations_csv(mutations, path, filter=True)</code>","text":"<p>Prep and write the mutations CSV to the given filepath.</p> <p>Parameters:</p> Name Type Description Default <code>mutations</code> <code>DataFrame</code> <p>Muations CSV</p> required <code>path</code> <code>str</code> <p>Path to write to</p> required <code>filter</code> <code>bool</code> <p>Whether to filter nucleotide changes</p> <code>True</code> Source code in <code>gnomonicus/gnomonicus_lib.py</code> <pre><code>def write_mutations_csv(\n    mutations: pd.DataFrame, path: str, filter: bool = True\n) -&gt; None:\n    \"\"\"Prep and write the mutations CSV to the given filepath.\n\n    Args:\n        mutations (pd.DataFrame): Muations CSV\n        path (str): Path to write to\n        filter (bool, optional): Whether to filter nucleotide changes\n    \"\"\"\n    # Reorder the columns\n    mutations = mutations[\n        [\n            \"uniqueid\",\n            \"gene\",\n            \"mutation\",\n            \"ref\",\n            \"alt\",\n            \"nucleotide_number\",\n            \"nucleotide_index\",\n            \"gene_position\",\n            \"codes_protein\",\n            \"indel_length\",\n            \"indel_nucleotides\",\n            \"amino_acid_number\",\n            \"amino_acid_sequence\",\n            \"number_nucleotide_changes\",\n        ]\n    ]\n\n    # As we have concated several dataframes, the index is 0,1,2,0,1...\n    # Reset it so that we can use it to delete\n    mutations.reset_index(drop=True, inplace=True)\n    mutations_ = copy.deepcopy(mutations)\n    if filter:\n        # Filter out nucleotide variants from synonymous mutations to avoid duplication of data\n        to_drop = []\n        for idx2, row in mutations_.iterrows():\n            if (\n                row[\"codes_protein\"]\n                and row[\"ref\"] is not None\n                and row[\"alt\"] is not None\n            ):\n                # Protein coding so check if nucleotide within coding region\n                if len(row[\"ref\"]) == 1:\n                    # Nucleotide SNP\n                    to_drop.append(idx2)\n        mutations_.drop(index=to_drop, inplace=True)\n    # Save it as CSV\n    mutations_.to_csv(path, index=False)\n</code></pre>"}]}